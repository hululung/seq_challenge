{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le Challenge\n",
    "Pour les jeux olympiques de 2024 Bouygues Telecom va d√©ployer de nouveaux √©quipements r√©seau sur les zones des comp√©titions et des √©v√®nements pour g√©rer le nombre important de connexions.\n",
    "Ces √©quipements sont d'un type nouveau et leur bon fonctionnement doit √™tre supervis√© en temps r√©√©l afin de s'assurer de la bonne exp√©rience des utilisateurs du r√©seau.\n",
    "Ils disposent d'une interface websocket qui permet la r√©cup√©ration en temps r√©√©l des indicateur syst√®me.\n",
    "Le constructeur ne fourni pas de supervision et vous devez donc en d√©velopper une.\n",
    "Heureusement la documentation est fournie par le constructeur : "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÊúâÊó∂ÂÄôÔºåÊÇ®ÂèØ‰ª•ÈÄöËøáËøô‰∏™ÁïåÈù¢Êé•Êî∂Âà∞Á≥ªÁªüÁä∂ÊÄÅÁöÑ4‰∏™ÂÄº„ÄÇ\n",
    "Ëøô‰∫õÂÄºÈùûÂ∏∏ÈáçË¶ÅÔºåÁ¨¨‰∏Ä‰∏™ÂÄºÔºåÁ¨¨‰∫å‰∏™ÂÄºÔºåÁ¨¨‰∏â‰∏™ÂÄºÂíåÁ¨¨Âõõ‰∏™ÂÄº‰æùÊ¨°ÊéíÂàó„ÄÇ\n",
    "ÊÇ®ÂèØ‰ª•ÈÄöËøáËøô‰∫õÂÄº‰∫ÜËß£Á≥ªÁªüÊòØÂê¶Ê≠£Â∏∏ËøêË°åÔºåÊúâÊó∂Â¶ÇÊûúË¥üËΩΩËøáÂ§ßÔºåËøô‰∫õÂÄº‰ºöÊúâÊâÄ‰∏çÂêå„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un canevas d'un syst√®me de supervision est fourni pour vous aider dans cette t√¢che... A vous de jouer !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque vous voyez `### .... ` il manque du code.<br>\n",
    "Il en manque peut √™tre √† d'autres endroits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import websocket\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "import torch\n",
    "from torch import tensor\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si une GPU est disponible, elle sera utilis√©e sinon les calculs seront faits sur CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device.type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeasureHandler\n",
    "Ceci est la fonction de traitement de chaque nouvelle mesure re√ßue.\n",
    "De base elle ne fait que tracer les mesures re√ßues, il faudra la faire √©voluer pour appeler le mod√®le entrain√© et √©valuer si le comportement est typique ou non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeasureHandler:\n",
    "\n",
    "    #Nombre de valeurs √† conserver pour l'affichage\n",
    "    buffer_size=200\n",
    "\n",
    "    sequence_size=50\n",
    "\n",
    "    def __init__(self):\n",
    "        self.fig, (self.ax) = plt.subplots(1, figsize=(14, 7))\n",
    "\n",
    "        # plot avec 2 axes y\n",
    "        self.ax2 = self.ax.twinx()\n",
    "  \n",
    "        self.a=[]\n",
    "        self.b=[]\n",
    "        self.c=[]\n",
    "        self.d=[]\n",
    "\n",
    "        self.history=[]\n",
    "   \n",
    "        self.init_ax()\n",
    "\n",
    "        self.cnt=0\n",
    "\n",
    "    def init_ax(self):\n",
    "        \n",
    "        self.ax.clear()  \n",
    "        self.ax2.clear()  \n",
    "\n",
    "        self.ax2.yaxis.set_label_position(\"right\")\n",
    "\n",
    "        self.ax2.set_ylabel('Reconstruction loss')\n",
    "        self.ax.set_ylabel('Input value')\n",
    "                    \n",
    "        #Echelle de gauche          \n",
    "        self.ax.set_ylim(0, 1)\n",
    "\n",
    "        #Echelle de droite\n",
    "        self.ax2.set_ylim(0, 1e-4)\n",
    "        \n",
    "        #Echelle des abscisses\n",
    "        self.ax.set_xlim(-self.buffer_size, 0)\n",
    "\n",
    "\n",
    "    def handleMeasure(self,info):\n",
    "        \n",
    "        self.history.append(info)        \n",
    "\n",
    "        if len(self.history)>self.sequence_size:\n",
    "            self.history=self.history[-self.sequence_size:]\n",
    "\n",
    "        self.a.append(info[0])\n",
    "        self.b.append(info[1])\n",
    "        self.c.append(info[2])\n",
    "        self.d.append(info[3])\n",
    "\n",
    "        #Conserver les derni√®res valeurs\n",
    "        if len(self.a)>self.buffer_size :\n",
    "            self.a=self.a[-self.buffer_size:]\n",
    "            self.b=self.b[-self.buffer_size:]\n",
    "            self.c=self.c[-self.buffer_size:]\n",
    "            self.d=self.d[-self.buffer_size:]\n",
    "                        \n",
    "        #N√©cessaire pour un affichage correct et dynamique\n",
    "        self.init_ax()\n",
    "    \n",
    "        #G√©n√©rer les abscisses √† la bonne dimension\n",
    "        x=[*range(-len(self.a),0)]\n",
    "\n",
    "        self.ax.plot(x,self.d,'co-')\n",
    "        self.ax.plot(x,self.c,'go-')\n",
    "        self.ax.plot(x,self.b,'yo-')\n",
    "        self.ax.plot(x,self.a,'bo-')\n",
    "\n",
    "        #Mise √† jour de l'affichage\n",
    "        clear_output(wait = True)\n",
    "        display(self.fig)\n",
    "\n",
    "        #Nombre total de mesures re√ßues\n",
    "        self.cnt = self.cnt+1\n",
    "\n",
    "\n",
    "    #Fonction par d√©faut de la classe\n",
    "    def __call__(self, *args, **kwds) :\n",
    "        self.handleMeasure(args[0])    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cellule principale\n",
    "Ceci est la connexion √† l'√©quipement √† superviser par websocket et l'invocation du MeasureHandler √† chaque mesure.<br>\n",
    "C'est cette cellule qu'il faut lancer comme traitemement principal.<br>\n",
    "Il n'y a √† priori aucune raison de modifier ce code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = MeasureHandler()\n",
    "\n",
    "def on_message(ws, message):\n",
    "    info =json.loads(message)\n",
    "    \n",
    "    handler(info)\n",
    "\n",
    "def on_error(ws, error):\n",
    "    print(error)\n",
    "\n",
    "def on_close(ws, close_status_code, close_msg):\n",
    "    print(\"### closed ###\")\n",
    "\n",
    "def on_open(ws):\n",
    "    print(\"### connected ###\")\n",
    "\n",
    "ws = websocket.WebSocketApp(\"wss://iot.2bytl.fr/metrics\",\n",
    "                              on_open=on_open,\n",
    "                              on_message=on_message,\n",
    "                              on_error=on_error,\n",
    "                              on_close=on_close)\n",
    "try:\n",
    "    ws.run_forever()\n",
    "except:\n",
    "    pass\n",
    "    print('### stopped ###')    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donn√©es d'entrainement\n",
    "Heureusement un stagiaire a pris le temps de collecter 200 000 mesures de l'√©quipement en fonctionnement nominal.<br>\n",
    "L'√©quipement semble toujours bien fonctionner et aucune mesure anormale n'a pu √™tre collect√©e.\n",
    "\n",
    "Les donn√©es ne sont pas en trop grand nombre et peuvent √™tre facilement charg√©es dans un dataframe Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sample.csv',header=None,names=[\"Val1\", \"Val2\", \"Val3\", \"Val4\"])\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par chance les valeurs sont d√©j√† entre 0 et 1, donc pas besoin de normaliser."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction du mod√®le\n",
    "Vous n'avez pas de donn√©es d'un √©quipement qui dysfonctionne... Vous ne pouvez donc pas envisager un entrainement supervis√© de \"classifier\" avec des classes de sortie type OK - KO.\n",
    "Pour traiter ce type de probl√®me vous devez apprendre √† un r√©seau de neuronne √† reconstruire la \"normalit√©\". Ce type de r√©seau de neuronne s'appelle en Auto Encoder car il apprend √† encoder puis √† d√©coder le signal d'entr√©e pour le reproduire au mieux.<br>\n",
    "https://fr.wikipedia.org/wiki/Auto-encodeur\n",
    "\n",
    "Dans ce cas, il faut traiter des s√©quences car c'est la suite des valeurs qu'il faut examiner plut√¥t que leur valeur instantann√©e.\n",
    "\n",
    "Pour traiter les s√©quences num√©riques les r√©seaux de neuronnes les plus classiques sont les LSTM: Long Short Term Memory.<br>\n",
    "https://fr.wikipedia.org/wiki/R%C3%A9seau_de_neurones_r%C3%A9currents\n",
    "\n",
    "Une solution pour assurer cette supervision sans avoir observ√© de cas particulier de dysfonctionnement est donc un LSTM - Autoencoder:\n",
    "<div>\n",
    "<img src=\"https://www.researchgate.net/profile/Hoang_Duy_Trinh2/publication/336594630/figure/fig2/AS:814792885420033@1571273170513/LSTM-Autoencoder-for-Anomaly-Detection.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici les pr√©conisations pour construire le mod√®le : (les chiffres donn√©s sont des ordres de grandeur qui peuvent √™tre modifi√©s)<br>\n",
    "Fournir un param√®tre au constructeur qui est le nombre de features (ici 4)\n",
    "Cr√©er un encodeur √† 2 niveaux: <br>\n",
    "1. LSTM nb_features --> nb_features * 40\n",
    "2. LSTM nb_features *40 --> nb_features * 15\n",
    "\n",
    "Par rapport au sch√©ma ci-dessus nb_features * 15 est donc la repr√©sentation compress√©e (z)\n",
    "\n",
    "Cr√©er un d√©codeur √† 2 niveaux: <br>\n",
    "1. LSTM nb_features * 15 --> nb_features * 40\n",
    "2. Dense (linear) nb_features * 40 --> nb_features\n",
    "\n",
    "Il aurait √©t√© possible d'utiliser 2 LSTM dans le d√©codeur mais il est plus l√©ger de finir par un r√©seau dense et cela devrait donner des r√©sultats acceptables.\n",
    "\n",
    "La documentation du LSTM : https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "Il est important d'utiliser l'argument batch_first = True sans quoi la g√©n√©ration des donn√©es d'entr√©e est plus complexe<br>\n",
    "Les param√®tres √† fixer sont input_size et hidden_size<br>\n",
    "Vous n'utiliserez ni les hidden_state ni les cell_state dans cet exemple.<br>\n",
    "Regardez bien le format de sortie de l'appel au LSTM.<br>\n",
    "\n",
    "La documentation de la couche dense (Linear) : https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "\n",
    "Vous pourrez trouver des exemples d'auto-encodeur LSTM avec un passage uniquement du dernier niveau de hidden_state entre l'encodeur et le d√©codeur.<br>\n",
    "Ceci est un sch√©ma courant mais qui ne fonctionnera pas bien dans notre cas, en particulier √† cause de la courbe bleue (Val1) qui est tr√®s discontinue. L'auto-encodeur a besoin que l'ensemble de la s√©quence soit transmis pour fonctionner correctement.\n",
    "\n",
    "Regardez un exemple de construction de r√©seau de neurones :<br>\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "\n",
    "Si vous vous perdez dans les tailles utilisez quelque chose comme `print(x.shape)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperviserModel (nn.Module):\n",
    "\n",
    "    def __init__(self, nb_features):\n",
    "        super().__init__()\n",
    "        self.nb_features = nb_features  # this is the number of features\n",
    "        self.hidden_size = nb_features*40\n",
    "        self.encoded_size = nb_features*15\n",
    "\n",
    "        ### ....\n",
    "\n",
    "    #M√©thode forward : sortie = f(entr√©e)\n",
    "    #Sortie et entr√©e on la m√™me \"forme\" : batch_size, sequence_size, nb_features\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        ### ....\n",
    "\n",
    "        return decoded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√©paration des donn√©es d'entrainement\n",
    "Pour entrainer un LSTM il faut lui fournir des s√©quences.\n",
    "La taille des s√©quences est importante pour son bon entrainement:\n",
    "* Trop courtes il aura du mal √† bien comprendre l'√©volution des valeurs.\n",
    "* Trop longues l'entrainement sera tr√®s lourd et il ne sera pas assez g√©n√©rique.\n",
    "\n",
    "Avec pytorch la classe qui sert √† acc√©der aux donn√©es est Dataset.<br>\n",
    "Le Dataset doit fournir des donn√©es de type `tensor` et il est pr√©f√©rable pour les performances de faire une seule fois la transformation sur les donn√©es d'entr√©e.\n",
    "\n",
    "La m√©thode `__getitem__` est appel√©e pour r√©cup√©rer chaque valeur √† l'index i<br>\n",
    "Pour avoir des s√©quence vous devrez retourner une portion des donn√©es d'entr√©e entre i et i+seqlen\n",
    "\n",
    "La m√©thode `__len__` est appel√©e pour r√©cup√©rer la longueur du dataset\n",
    "\n",
    "Attention √† ne pas d√©passer la longueur totale de votre dataframe contenant les donn√©es d'entrainement üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, dataframe, sequence_length):\n",
    "        self.features = dataframe.columns\n",
    "        self.seqlen = sequence_length\n",
    "        #Passage en tensor pytorch une fois pour toute\n",
    "        self.x = tensor(dataframe[self.features].values).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        ### ....\n",
    "\n",
    "    def __getitem__(self, i): \n",
    "        ### ...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixez une longueur de s√©quence entre 5 et 10 par exemple et cr√©ez votre dataset d'entrainement<br>\n",
    "Affichez la taille d'un enregistrement qui devrait √™tre [sequence_length,nb_features]<br>\n",
    "Affichez quelques valeurs pour v√©rifier que le format est correct<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = ### ....\n",
    "\n",
    "train_dataset = SequenceDataset(\n",
    "    data,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "print (train_dataset[10].shape)\n",
    "\n",
    "for i in range (10,12):\n",
    "    print(train_dataset[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un r√©seau de neurone ne s'entraine jamais valeur par valeur car il aurait trop de mal √† converger.<br>\n",
    "Une notion cl√© pour un entrainement est la taille de batch. Cela repr√©sente le nombre d'enregistrements qui font √™tre pris dans l'√©valuation de l'erreur (loss) et la back-propagation qui ajustera les poids des diff√©rentes cellules en fonction des gradiants.<br>\n",
    "Dans pytorch la classe qui sert en g√©n√©ral √† charger par batch le dataset dans l'entrainement est le `DataLoader` <br>\n",
    "Il prend en entr√©e le dataset et la taille de batch<br>\n",
    "Il est en g√©n√©ral important de positionner shuffle=True afin que les donn√©es soient pass√©es al√©atoirement et que l'entrainement ne voit pas toujours passer les donn√©es regroup√©es de la m√™me mani√®re suivant les epochs(passage de l'ensemble du dataset)<br>\n",
    "https://pytorch.org/docs/stable/data.html\n",
    "\n",
    "V√©rifiez la taille d'un enregistrement qui devrait √™tre (batch_size,sequence_length,nb_features)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = ### ....\n",
    "x = next(iter(train_loader))\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction d'entrainement\n",
    "\n",
    "Pour entrainer un mod√®le il faut plusieurs √©l√©ments cl√©:\n",
    "* Le dataloader qui permet de s√©lectionner les lots (batchs) de valeurs\n",
    "* Un optimizer qui sera en charge de modifier les poids des cellules du r√©seau\n",
    "* Une loss-function qui sera en charge de calculer la valeur de l'erreur (loss)\n",
    "* Optionnellement un scheduler qui sera en charge de faire √©voluer le taux d'apprentissage (learning_rate) en g√©n√©ral en le baissant au cours de l'apprentissage pour aider √† la convergence du mod√®le\n",
    "\n",
    "Assez classiquement on utilisera une loss_function MSE (MeanSquareError) et un optimizer Adam.<br>\n",
    "Pour faire simple on prend ici une baisse exponentielle du taux d'apprentissage\n",
    "\n",
    "Avant de rentrer dans la boucle le mod√®le doit √™tre positionn√© en mode apprentissage afin qu'il maintienne les gradients\n",
    "\n",
    "Pour chaque batch \n",
    "* reinitialiser les gradients\n",
    "* copier la s√©quence vers la gpu si n√©cessaire\n",
    "* calculer la sortie du mod√®le pour seq\n",
    "* calculer la loss de la recontruction de la s√©quence\n",
    "* faire la back-propagation\n",
    "* faire avancer l'optimizer\n",
    "* faire avancer le scheduler\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/introyt/trainingyt.html#the-training-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, n_epochs):\n",
    "  optimizer = Adam(model.parameters(), lr=1e-2)\n",
    "  scheduler = ExponentialLR(optimizer, gamma=0.9995)\n",
    "  loss_func =  nn.MSELoss().to(device)\n",
    "\n",
    "  model.train() #on positionne le mod√®le en mode entrainement pour le calcul des gradients\n",
    "\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    for i,seq in enumerate(loader):\n",
    "\n",
    "      ### ....\n",
    "\n",
    "      #Affichage toutes les 100 it√©rations\n",
    "      if i%100==0 : \n",
    "        print(f'Epoch {epoch}-{i}  lr {scheduler.get_last_lr()} train loss {loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement\n",
    "* Cr√©er le mod√®le avec 4 features\n",
    "* Copier le mod√®le sur GPU si disponible\n",
    "* Faire l'entrainement. 1 epoch donne d√©j√† un r√©sultat utilisable vu le nombre de donn√©es d'entrainement. 2 epochs sera mieux si vous avez le temps.\n",
    "\n",
    "L'entrainement ne devrait pas prendre plus de 5 minutes par epoch sur un ordinateur personnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ### ...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarder le mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recharger le mod√®le et afficher sa structrure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('model.pt')\n",
    "summary(model)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation du mod√®le\n",
    "Cr√©er une fonction permettant d'√©valuer la \"Loss\" de la reconstruction d'une s√©quence.\n",
    "Rappelez vous que le mod√®le attend un tenseur de taille (batch_size,sequence_length,nb_features)\n",
    "Vous devez donc ajouter une dimension batch √† la s√©quence avant de la passer au mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sequence(seq) :\n",
    "    loss_function =  nn.MSELoss().to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = seq.to(device)\n",
    "        x = x.unsqueeze(0) #Remet une dimension ce qui revient √† une taille de batch de 1\n",
    "        outputs = model.forward(x)\n",
    "        loss = loss_function(outputs,x).item()\n",
    "        return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour √©valuer ce que donne le mod√®le, cr√©er une fonction qui traite quelques s√©quences issues d'un dataSet. \n",
    "La longueur de la s√©quence √©valu√©e peut √™tre modif√©e. Regardez graphiquement les valeurs re√ßues de l'√©quipement et √©valuer une taille de s√©quence qui serait √† v√©rifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_stats(data):\n",
    "\n",
    "    test_seq_len = ### ....\n",
    "\n",
    "    losses=[]\n",
    "\n",
    "    for a in range (0,500):\n",
    "        d = data.iloc[a*100:(a*100+test_seq_len)].values\n",
    "        v = tensor(d).float()\n",
    "        l1 = check_sequence(v)\n",
    "        losses.append(l1)\n",
    "\n",
    "    print ('max loss',np.max(losses))\n",
    "    print ('min loss',np.min(losses))\n",
    "    print ('mean loss',np.mean(losses))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluer ce que cela donne sur les donn√©es disponibles..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_stats(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N'ayant aucune id√©e de ce qui se passe lors d'un dysfonctionnement, ajouter un peu de bruit √† nos donn√©es puis refaire un test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.copy()\n",
    "data2 = ### ...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayer √©galement des donn√©es totalement al√©atoires..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = ### ...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenenant vous avez les ordres de grandeur de la \"reconstruction loss\" pour des valeurs habituelles, en √©cart ou aberrantes.\n",
    "Cela doit vous permettre de fixer le seuil √† partir duquel vous allez consid√©rer que le syst√®me dysfonctionne."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finaliser le superviseur\n",
    "\n",
    "Afin d'avoir une supervision, il reste √† int√©grer la fonction check_sequence dans le measure_hander<br>\n",
    "\n",
    "Tracer un histogramme pour la loss en utilisant l'axe de droite (ax2)\n",
    "\n",
    "Fixer un seuil d'anomalie, faire en sorte que les barres soient vertes pour les valeurs en dessous du seuil et rouges au dessus.<br>\n",
    "https://stackoverflow.com/questions/69043592/how-to-choose-bar-color-if-value-is-positive-or-negative\n",
    "\n",
    "L'√©valuation du mod√®le est couteuse en cpu, temps, √©nergie.<br>\n",
    "Si vous faites l'√©valuation pour chaque nouvelle mesure vous n'aurez pas un r√©sultat tr√®s √©co-responsable et de plus votre superviseur risque de prendre du retard par rapport au temmps r√©√©l. Vous allez √™tre amen√©s √† n'√©valuer la s√©quence que tous les n points. Tous les 3 points est une bonne premi√®re approche."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
