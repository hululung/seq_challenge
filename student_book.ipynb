{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le Challenge\n",
    "Pour les jeux olympiques de 2024 Bouygues Telecom va déployer de nouveaux équipements réseau sur les zones des compétitions et des évènements pour gérer le nombre important de connexions.\n",
    "Ces équipements sont d'un type nouveau et leur bon fonctionnement doit être supervisé en temps réél afin de s'assurer de la bonne expérience des utilisateurs du réseau.\n",
    "Ils disposent d'une interface websocket qui permet la récupération en temps réél des indicateur système.\n",
    "Le constructeur ne fourni pas de supervision et vous devez donc en développer une.\n",
    "Heureusement la documentation est fournie par le constructeur : "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时候，您可以通过这个界面接收到系统状态的4个值。\n",
    "这些值非常重要，第一个值，第二个值，第三个值和第四个值依次排列。\n",
    "您可以通过这些值了解系统是否正常运行，有时如果负载过大，这些值会有所不同。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un canevas d'un système de supervision est fourni pour vous aider dans cette tâche... A vous de jouer !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque vous voyez `### .... ` il manque du code.<br>\n",
    "Il en manque peut être à d'autres endroits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import websocket\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "import torch\n",
    "from torch import tensor\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si une GPU est disponible, elle sera utilisée sinon les calculs seront faits sur CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device.type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeasureHandler\n",
    "Ceci est la fonction de traitement de chaque nouvelle mesure reçue.\n",
    "De base elle ne fait que tracer les mesures reçues, il faudra la faire évoluer pour appeler le modèle entrainé et évaluer si le comportement est typique ou non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeasureHandler:\n",
    "\n",
    "    #Nombre de valeurs à conserver pour l'affichage\n",
    "    buffer_size=200\n",
    "\n",
    "    sequence_size=50\n",
    "\n",
    "    def __init__(self):\n",
    "        self.fig, (self.ax) = plt.subplots(1, figsize=(14, 7))\n",
    "\n",
    "        # plot avec 2 axes y\n",
    "        self.ax2 = self.ax.twinx()\n",
    "  \n",
    "        self.a=[]\n",
    "        self.b=[]\n",
    "        self.c=[]\n",
    "        self.d=[]\n",
    "\n",
    "        self.history=[]\n",
    "   \n",
    "        self.init_ax()\n",
    "\n",
    "        self.cnt=0\n",
    "\n",
    "    def init_ax(self):\n",
    "        \n",
    "        self.ax.clear()  \n",
    "        self.ax2.clear()  \n",
    "\n",
    "        self.ax2.yaxis.set_label_position(\"right\")\n",
    "\n",
    "        self.ax2.set_ylabel('Reconstruction loss')\n",
    "        self.ax.set_ylabel('Input value')\n",
    "                    \n",
    "        #Echelle de gauche          \n",
    "        self.ax.set_ylim(0, 1)\n",
    "\n",
    "        #Echelle de droite\n",
    "        self.ax2.set_ylim(0, 1e-4)\n",
    "        \n",
    "        #Echelle des abscisses\n",
    "        self.ax.set_xlim(-self.buffer_size, 0)\n",
    "\n",
    "\n",
    "    def handleMeasure(self,info):\n",
    "        \n",
    "        self.history.append(info)        \n",
    "\n",
    "        if len(self.history)>self.sequence_size:\n",
    "            self.history=self.history[-self.sequence_size:]\n",
    "\n",
    "        self.a.append(info[0])\n",
    "        self.b.append(info[1])\n",
    "        self.c.append(info[2])\n",
    "        self.d.append(info[3])\n",
    "\n",
    "        #Conserver les dernières valeurs\n",
    "        if len(self.a)>self.buffer_size :\n",
    "            self.a=self.a[-self.buffer_size:]\n",
    "            self.b=self.b[-self.buffer_size:]\n",
    "            self.c=self.c[-self.buffer_size:]\n",
    "            self.d=self.d[-self.buffer_size:]\n",
    "                        \n",
    "        #Nécessaire pour un affichage correct et dynamique\n",
    "        self.init_ax()\n",
    "    \n",
    "        #Générer les abscisses à la bonne dimension\n",
    "        x=[*range(-len(self.a),0)]\n",
    "\n",
    "        self.ax.plot(x,self.d,'co-')\n",
    "        self.ax.plot(x,self.c,'go-')\n",
    "        self.ax.plot(x,self.b,'yo-')\n",
    "        self.ax.plot(x,self.a,'bo-')\n",
    "\n",
    "        #Mise à jour de l'affichage\n",
    "        clear_output(wait = True)\n",
    "        display(self.fig)\n",
    "\n",
    "        #Nombre total de mesures reçues\n",
    "        self.cnt = self.cnt+1\n",
    "\n",
    "\n",
    "    #Fonction par défaut de la classe\n",
    "    def __call__(self, *args, **kwds) :\n",
    "        self.handleMeasure(args[0])    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cellule principale\n",
    "Ceci est la connexion à l'équipement à superviser par websocket et l'invocation du MeasureHandler à chaque mesure.<br>\n",
    "C'est cette cellule qu'il faut lancer comme traitemement principal.<br>\n",
    "Il n'y a à priori aucune raison de modifier ce code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = MeasureHandler()\n",
    "\n",
    "def on_message(ws, message):\n",
    "    info =json.loads(message)\n",
    "    \n",
    "    handler(info)\n",
    "\n",
    "def on_error(ws, error):\n",
    "    print(error)\n",
    "\n",
    "def on_close(ws, close_status_code, close_msg):\n",
    "    print(\"### closed ###\")\n",
    "\n",
    "def on_open(ws):\n",
    "    print(\"### connected ###\")\n",
    "\n",
    "ws = websocket.WebSocketApp(\"wss://iot.2bytl.fr/metrics\",\n",
    "                              on_open=on_open,\n",
    "                              on_message=on_message,\n",
    "                              on_error=on_error,\n",
    "                              on_close=on_close)\n",
    "try:\n",
    "    ws.run_forever()\n",
    "except:\n",
    "    pass\n",
    "    print('### stopped ###')    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données d'entrainement\n",
    "Heureusement un stagiaire a pris le temps de collecter 200 000 mesures de l'équipement en fonctionnement nominal.<br>\n",
    "L'équipement semble toujours bien fonctionner et aucune mesure anormale n'a pu être collectée.\n",
    "\n",
    "Les données ne sont pas en trop grand nombre et peuvent être facilement chargées dans un dataframe Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sample.csv',header=None,names=[\"Val1\", \"Val2\", \"Val3\", \"Val4\"])\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par chance les valeurs sont déjà entre 0 et 1, donc pas besoin de normaliser."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction du modèle\n",
    "Vous n'avez pas de données d'un équipement qui dysfonctionne... Vous ne pouvez donc pas envisager un entrainement supervisé de \"classifier\" avec des classes de sortie type OK - KO.\n",
    "Pour traiter ce type de problème vous devez apprendre à un réseau de neuronne à reconstruire la \"normalité\". Ce type de réseau de neuronne s'appelle en Auto Encoder car il apprend à encoder puis à décoder le signal d'entrée pour le reproduire au mieux.<br>\n",
    "https://fr.wikipedia.org/wiki/Auto-encodeur\n",
    "\n",
    "Dans ce cas, il faut traiter des séquences car c'est la suite des valeurs qu'il faut examiner plutôt que leur valeur instantannée.\n",
    "\n",
    "Pour traiter les séquences numériques les réseaux de neuronnes les plus classiques sont les LSTM: Long Short Term Memory.<br>\n",
    "https://fr.wikipedia.org/wiki/R%C3%A9seau_de_neurones_r%C3%A9currents\n",
    "\n",
    "Une solution pour assurer cette supervision sans avoir observé de cas particulier de dysfonctionnement est donc un LSTM - Autoencoder:\n",
    "<div>\n",
    "<img src=\"https://www.researchgate.net/profile/Hoang_Duy_Trinh2/publication/336594630/figure/fig2/AS:814792885420033@1571273170513/LSTM-Autoencoder-for-Anomaly-Detection.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici les préconisations pour construire le modèle : (les chiffres donnés sont des ordres de grandeur qui peuvent être modifiés)<br>\n",
    "Fournir un paramètre au constructeur qui est le nombre de features (ici 4)\n",
    "Créer un encodeur à 2 niveaux: <br>\n",
    "1. LSTM nb_features --> nb_features * 40\n",
    "2. LSTM nb_features *40 --> nb_features * 15\n",
    "\n",
    "Par rapport au schéma ci-dessus nb_features * 15 est donc la représentation compressée (z)\n",
    "\n",
    "Créer un décodeur à 2 niveaux: <br>\n",
    "1. LSTM nb_features * 15 --> nb_features * 40\n",
    "2. Dense (linear) nb_features * 40 --> nb_features\n",
    "\n",
    "Il aurait été possible d'utiliser 2 LSTM dans le décodeur mais il est plus léger de finir par un réseau dense et cela devrait donner des résultats acceptables.\n",
    "\n",
    "La documentation du LSTM : https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "Il est important d'utiliser l'argument batch_first = True sans quoi la génération des données d'entrée est plus complexe<br>\n",
    "Les paramètres à fixer sont input_size et hidden_size<br>\n",
    "Vous n'utiliserez ni les hidden_state ni les cell_state dans cet exemple.<br>\n",
    "Regardez bien le format de sortie de l'appel au LSTM.<br>\n",
    "\n",
    "La documentation de la couche dense (Linear) : https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "\n",
    "Vous pourrez trouver des exemples d'auto-encodeur LSTM avec un passage uniquement du dernier niveau de hidden_state entre l'encodeur et le décodeur.<br>\n",
    "Ceci est un schéma courant mais qui ne fonctionnera pas bien dans notre cas, en particulier à cause de la courbe bleue (Val1) qui est très discontinue. L'auto-encodeur a besoin que l'ensemble de la séquence soit transmis pour fonctionner correctement.\n",
    "\n",
    "Regardez un exemple de construction de réseau de neurones :<br>\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "\n",
    "Si vous vous perdez dans les tailles utilisez quelque chose comme `print(x.shape)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperviserModel (nn.Module):\n",
    "\n",
    "    def __init__(self, nb_features):\n",
    "        super().__init__()\n",
    "        self.nb_features = nb_features  # this is the number of features\n",
    "        self.hidden_size = nb_features*40\n",
    "        self.encoded_size = nb_features*15\n",
    "\n",
    "        ### ....\n",
    "\n",
    "    #Méthode forward : sortie = f(entrée)\n",
    "    #Sortie et entrée on la même \"forme\" : batch_size, sequence_size, nb_features\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        ### ....\n",
    "\n",
    "        return decoded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données d'entrainement\n",
    "Pour entrainer un LSTM il faut lui fournir des séquences.\n",
    "La taille des séquences est importante pour son bon entrainement:\n",
    "* Trop courtes il aura du mal à bien comprendre l'évolution des valeurs.\n",
    "* Trop longues l'entrainement sera très lourd et il ne sera pas assez générique.\n",
    "\n",
    "Avec pytorch la classe qui sert à accéder aux données est Dataset.<br>\n",
    "Le Dataset doit fournir des données de type `tensor` et il est préférable pour les performances de faire une seule fois la transformation sur les données d'entrée.\n",
    "\n",
    "La méthode `__getitem__` est appelée pour récupérer chaque valeur à l'index i<br>\n",
    "Pour avoir des séquence vous devrez retourner une portion des données d'entrée entre i et i+seqlen\n",
    "\n",
    "La méthode `__len__` est appelée pour récupérer la longueur du dataset\n",
    "\n",
    "Attention à ne pas dépasser la longueur totale de votre dataframe contenant les données d'entrainement 😉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, dataframe, sequence_length):\n",
    "        self.features = dataframe.columns\n",
    "        self.seqlen = sequence_length\n",
    "        #Passage en tensor pytorch une fois pour toute\n",
    "        self.x = tensor(dataframe[self.features].values).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        ### ....\n",
    "\n",
    "    def __getitem__(self, i): \n",
    "        ### ...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixez une longueur de séquence entre 5 et 10 par exemple et créez votre dataset d'entrainement<br>\n",
    "Affichez la taille d'un enregistrement qui devrait être [sequence_length,nb_features]<br>\n",
    "Affichez quelques valeurs pour vérifier que le format est correct<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = ### ....\n",
    "\n",
    "train_dataset = SequenceDataset(\n",
    "    data,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "print (train_dataset[10].shape)\n",
    "\n",
    "for i in range (10,12):\n",
    "    print(train_dataset[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un réseau de neurone ne s'entraine jamais valeur par valeur car il aurait trop de mal à converger.<br>\n",
    "Une notion clé pour un entrainement est la taille de batch. Cela représente le nombre d'enregistrements qui font être pris dans l'évaluation de l'erreur (loss) et la back-propagation qui ajustera les poids des différentes cellules en fonction des gradiants.<br>\n",
    "Dans pytorch la classe qui sert en général à charger par batch le dataset dans l'entrainement est le `DataLoader` <br>\n",
    "Il prend en entrée le dataset et la taille de batch<br>\n",
    "Il est en général important de positionner shuffle=True afin que les données soient passées aléatoirement et que l'entrainement ne voit pas toujours passer les données regroupées de la même manière suivant les epochs(passage de l'ensemble du dataset)<br>\n",
    "https://pytorch.org/docs/stable/data.html\n",
    "\n",
    "Vérifiez la taille d'un enregistrement qui devrait être (batch_size,sequence_length,nb_features)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = ### ....\n",
    "x = next(iter(train_loader))\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction d'entrainement\n",
    "\n",
    "Pour entrainer un modèle il faut plusieurs éléments clé:\n",
    "* Le dataloader qui permet de sélectionner les lots (batchs) de valeurs\n",
    "* Un optimizer qui sera en charge de modifier les poids des cellules du réseau\n",
    "* Une loss-function qui sera en charge de calculer la valeur de l'erreur (loss)\n",
    "* Optionnellement un scheduler qui sera en charge de faire évoluer le taux d'apprentissage (learning_rate) en général en le baissant au cours de l'apprentissage pour aider à la convergence du modèle\n",
    "\n",
    "Assez classiquement on utilisera une loss_function MSE (MeanSquareError) et un optimizer Adam.<br>\n",
    "Pour faire simple on prend ici une baisse exponentielle du taux d'apprentissage\n",
    "\n",
    "Avant de rentrer dans la boucle le modèle doit être positionné en mode apprentissage afin qu'il maintienne les gradients\n",
    "\n",
    "Pour chaque batch \n",
    "* reinitialiser les gradients\n",
    "* copier la séquence vers la gpu si nécessaire\n",
    "* calculer la sortie du modèle pour seq\n",
    "* calculer la loss de la recontruction de la séquence\n",
    "* faire la back-propagation\n",
    "* faire avancer l'optimizer\n",
    "* faire avancer le scheduler\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/introyt/trainingyt.html#the-training-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, n_epochs):\n",
    "  optimizer = Adam(model.parameters(), lr=1e-2)\n",
    "  scheduler = ExponentialLR(optimizer, gamma=0.9995)\n",
    "  loss_func =  nn.MSELoss().to(device)\n",
    "\n",
    "  model.train() #on positionne le modèle en mode entrainement pour le calcul des gradients\n",
    "\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    for i,seq in enumerate(loader):\n",
    "\n",
    "      ### ....\n",
    "\n",
    "      #Affichage toutes les 100 itérations\n",
    "      if i%100==0 : \n",
    "        print(f'Epoch {epoch}-{i}  lr {scheduler.get_last_lr()} train loss {loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement\n",
    "* Créer le modèle avec 4 features\n",
    "* Copier le modèle sur GPU si disponible\n",
    "* Faire l'entrainement. 1 epoch donne déjà un résultat utilisable vu le nombre de données d'entrainement. 2 epochs sera mieux si vous avez le temps.\n",
    "\n",
    "L'entrainement ne devrait pas prendre plus de 5 minutes par epoch sur un ordinateur personnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ### ...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarder le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recharger le modèle et afficher sa structrure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('model.pt')\n",
    "summary(model)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation du modèle\n",
    "Créer une fonction permettant d'évaluer la \"Loss\" de la reconstruction d'une séquence.\n",
    "Rappelez vous que le modèle attend un tenseur de taille (batch_size,sequence_length,nb_features)\n",
    "Vous devez donc ajouter une dimension batch à la séquence avant de la passer au modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sequence(seq) :\n",
    "    loss_function =  nn.MSELoss().to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = seq.to(device)\n",
    "        x = x.unsqueeze(0) #Remet une dimension ce qui revient à une taille de batch de 1\n",
    "        outputs = model.forward(x)\n",
    "        loss = loss_function(outputs,x).item()\n",
    "        return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour évaluer ce que donne le modèle, créer une fonction qui traite quelques séquences issues d'un dataSet. \n",
    "La longueur de la séquence évaluée peut être modifée. Regardez graphiquement les valeurs reçues de l'équipement et évaluer une taille de séquence qui serait à vérifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_stats(data):\n",
    "\n",
    "    test_seq_len = ### ....\n",
    "\n",
    "    losses=[]\n",
    "\n",
    "    for a in range (0,500):\n",
    "        d = data.iloc[a*100:(a*100+test_seq_len)].values\n",
    "        v = tensor(d).float()\n",
    "        l1 = check_sequence(v)\n",
    "        losses.append(l1)\n",
    "\n",
    "    print ('max loss',np.max(losses))\n",
    "    print ('min loss',np.min(losses))\n",
    "    print ('mean loss',np.mean(losses))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluer ce que cela donne sur les données disponibles..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_stats(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N'ayant aucune idée de ce qui se passe lors d'un dysfonctionnement, ajouter un peu de bruit à nos données puis refaire un test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.copy()\n",
    "data2 = ### ...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayer également des données totalement aléatoires..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = ### ...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenenant vous avez les ordres de grandeur de la \"reconstruction loss\" pour des valeurs habituelles, en écart ou aberrantes.\n",
    "Cela doit vous permettre de fixer le seuil à partir duquel vous allez considérer que le système dysfonctionne."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finaliser le superviseur\n",
    "\n",
    "Afin d'avoir une supervision, il reste à intégrer la fonction check_sequence dans le measure_hander<br>\n",
    "\n",
    "Tracer un histogramme pour la loss en utilisant l'axe de droite (ax2)\n",
    "\n",
    "Fixer un seuil d'anomalie, faire en sorte que les barres soient vertes pour les valeurs en dessous du seuil et rouges au dessus.<br>\n",
    "https://stackoverflow.com/questions/69043592/how-to-choose-bar-color-if-value-is-positive-or-negative\n",
    "\n",
    "L'évaluation du modèle est couteuse en cpu, temps, énergie.<br>\n",
    "Si vous faites l'évaluation pour chaque nouvelle mesure vous n'aurez pas un résultat très éco-responsable et de plus votre superviseur risque de prendre du retard par rapport au temmps réél. Vous allez être amenés à n'évaluer la séquence que tous les n points. Tous les 3 points est une bonne première approche."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
